import joblib
import numpy as np

class ModelEnsemble:
    def __init__(self):
        # Load c√°c m√¥ h√¨nh ph√π h·ª£p
        self.rf_model = joblib.load("models/model_rf.pkl")
        self.xgb_model = joblib.load("models/model_xgb.pkl")
        self.mlp_model = joblib.load("models/model_mlp.pkl")
        
        # [OPTIONAL] V·∫´n load LR ƒë·ªÉ backward compatible
        try:
            self.lr_model = joblib.load("models/model_lr.pkl")
            self.has_lr = True
        except:
            self.has_lr = False
        
        # [FIX] CH·ªà d√πng 3 models t·ªët nh·∫•t, lo·∫°i b·ªè LinearRegression
        self.model_scores = {
            "XGBoost": 1.00,       # T·ªët nh·∫•t cho time series
            "RandomForest": 0.95,  # R·∫•t ·ªïn ƒë·ªãnh
            "MLP": 0.70,           # C√≥ th·ªÉ h·ªçc non-linear nh∆∞ng c·∫ßn c·∫©n th·∫≠n
        }
        
        self.outlier_threshold = 1.5  # Gi·∫£m t·ª´ 2.0 xu·ªëng 1.5 ƒë·ªÉ strict h∆°n

    def predict_all(self, input_data):
        """D·ª± ƒëo√°n t·ª´ c√°c m√¥ h√¨nh t·ªët"""
        preds = {
            "RandomForest": self.rf_model.predict(input_data)[0],
            "XGBoost": self.xgb_model.predict(input_data)[0],
            "MLP": self.mlp_model.predict(input_data)[0],
        }
        
        # [OPTIONAL] Th√™m LR ch·ªâ ƒë·ªÉ so s√°nh (kh√¥ng tham gia ensemble)
        if self.has_lr:
            preds["LinearRegression"] = self.lr_model.predict(input_data)[0]
        
        preds = {model: float(round(value, 4)) for model, value in preds.items()}
        return preds

    def predict_best(self, input_data):
        """
        Weighted average CH·ªà v·ªõi 3 models t·ªët (lo·∫°i b·ªè LR)
        """
        all_preds = self.predict_all(input_data)
        
        # CH·ªà l·∫•y predictions t·ª´ models trong ensemble
        preds = {k: v for k, v in all_preds.items() if k in self.model_scores}
        
        # Outlier detection
        values = list(preds.values())
        median_pred = np.median(values)
        
        adjusted_scores = {}
        for model, pred_value in preds.items():
            base_score = self.model_scores[model]
            
            if median_pred > 0.1:
                deviation_ratio = abs(pred_value - median_pred) / median_pred
                if deviation_ratio > self.outlier_threshold:
                    adjusted_scores[model] = base_score * 0.4  # Penalty m·∫°nh h∆°n
                else:
                    adjusted_scores[model] = base_score
            else:
                adjusted_scores[model] = base_score
        
        # Weighted average
        total_score = sum(adjusted_scores.values())
        weighted_sum = sum(preds[model] * adjusted_scores[model] for model in preds)
        weighted_avg = weighted_sum / total_score
        
        # Kh√¥ng √¢m
        weighted_avg = max(0, weighted_avg)
        
        # Smoothing cho gi√° tr·ªã th·∫•p
        if max(values) < 0.3:
            weighted_avg = min(weighted_avg, 0.25)
        
        weighted_avg = float(round(weighted_avg, 4))
        
        # Return all predictions ƒë·ªÉ log (bao g·ªìm c·∫£ LR n·∫øu c√≥)
        return weighted_avg, all_preds

    def predict_robust(self, input_data):
        """
        Robust prediction: Median c·ªßa XGBoost + RandomForest
        (Lo·∫°i b·ªè ho√†n to√†n MLP n·∫øu n√≥ l√† outlier)
        """
        all_preds = self.predict_all(input_data)
        preds = {k: v for k, v in all_preds.items() if k in self.model_scores}
        
        # T√≠nh median v√† MAD (Median Absolute Deviation)
        values = list(preds.values())
        median_val = np.median(values)
        mad = np.median([abs(v - median_val) for v in values])
        
        # Ch·ªâ l·∫•y c√°c predictions kh√¥ng ph·∫£i outlier
        threshold = 1.5 * mad if mad > 0 else 0.5
        filtered_preds = [v for v in values if abs(v - median_val) <= threshold]
        
        # N·∫øu filter qu√° nhi·ªÅu, √≠t nh·∫•t gi·ªØ l·∫°i 2 models t·ªët nh·∫•t
        if len(filtered_preds) < 2:
            sorted_by_score = sorted(preds.items(), key=lambda x: self.model_scores[x[0]], reverse=True)
            filtered_preds = [sorted_by_score[0][1], sorted_by_score[1][1]]
        
        robust_prediction = float(round(np.median(filtered_preds), 4))
        
        return robust_prediction, all_preds

    def predict_conservative(self, input_data):
        """
        [UPDATED] Conservative prediction: Ch·ªâ d√πng XGBoost + RandomForest
        Tr·ªçng s·ªë ƒê·ªòNG d·ª±a tr√™n hi·ªáu su·∫•t th·ª±c t·∫ø (self.model_scores)
        """
        all_preds = self.predict_all(input_data)
        
        xgb_pred = all_preds["XGBoost"]
        rf_pred = all_preds["RandomForest"]
        
        # 1. L·∫•y ƒëi·ªÉm s·ªë hi·ªán t·∫°i (ƒë∆∞·ª£c c·∫≠p nh·∫≠t qua feedback)
        score_xgb = self.model_scores.get("XGBoost", 1.0)
        score_rf = self.model_scores.get("RandomForest", 0.95)
        
        # 2. T√≠nh t·ªïng ƒë·ªÉ chu·∫©n h√≥a tr·ªçng s·ªë
        total_score = score_xgb + score_rf
        
        # Tr√°nh l·ªói chia cho 0 (d√π kh√≥ x·∫£y ra v√¨ min score l√† 0.3)
        if total_score == 0:
            weight_xgb = 0.55
            weight_rf = 0.45
        else:
            weight_xgb = score_xgb / total_score
            weight_rf = score_rf / total_score
            
        # 3. T√≠nh Weighted Average
        conservative_pred = (xgb_pred * weight_xgb + rf_pred * weight_rf)
        
        # Log t·ªâ l·ªá ƒë·ªÉ debug (c√≥ th·ªÉ b·ªè ƒëi khi ch·∫°y prod)
        # print(f"Weights used -> XGB: {weight_xgb:.2f}, RF: {weight_rf:.2f}")
        
        conservative_pred = float(round(max(0, conservative_pred), 4))
        
        return conservative_pred, all_preds

    def update_scores(self, predicted_details, actual_value):
        """
        C·∫≠p nh·∫≠t scores CH·ªà cho models trong ensemble
        LinearRegression b·ªã b·ªè qua
        """
        errors = {}
        for model_name, predicted_value in predicted_details.items():
            # Ch·ªâ update models trong ensemble
            if model_name not in self.model_scores:
                continue
                
            abs_error = abs(predicted_value - actual_value)
            if actual_value > 0.01:
                pct_error = abs_error / actual_value
            else:
                pct_error = abs_error
            errors[model_name] = pct_error

        if not errors:
            return
            
        sorted_models = sorted(errors.items(), key=lambda x: x[1])
        
        # Learning rate nh·ªè h∆°n v√¨ ch·ªâ c√≤n 3 models
        score_changes = [0.003, 0.001, -0.002]
        
        for idx, (model_name, error) in enumerate(sorted_models):
            change = score_changes[idx] if idx < len(score_changes) else score_changes[-1]
            
            # Bonus/Penalty
            if error < 0.05:
                change += 0.002
            if error > 0.5:
                change -= 0.003
            
            new_score = self.model_scores[model_name] + change
            self.model_scores[model_name] = round(max(0.3, min(1.0, new_score)), 4)

        print(f"üìä Updated scores (best: {min(errors.values()):.1%}, worst: {max(errors.values()):.1%})")
        print(f"   XGB: {self.model_scores['XGBoost']:.3f} | "
              f"RF: {self.model_scores['RandomForest']:.3f} | "
              f"MLP: {self.model_scores['MLP']:.3f}")